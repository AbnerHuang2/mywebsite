[{"content":"\u0026hellip;\nI love connecting with different people so if you want to say hi, I\u0026rsquo;ll be happy to meet you more! :)\n","date":"27 July 2022","permalink":"/","section":"","summary":"\u0026hellip;","title":""},{"content":"here is my posts.\n","date":"27 July 2022","permalink":"/posts/","section":"","summary":"here is my posts.","title":""},{"content":"","date":"27 July 2022","permalink":"/categories/","section":"Categories","summary":"","title":"Categories"},{"content":"","date":"27 July 2022","permalink":"/tags/mysql/","section":"Tags","summary":"","title":"Mysql"},{"content":"","date":"27 July 2022","permalink":"/categories/mysql/","section":"Categories","summary":"","title":"Mysql"},{"content":" 整体流程 # 主库发生数据变更，将数据写入到binlog文件中 从库I/O线程发起dump请求 主库I/O线程将指定位点的binlog推送到从库 从库I/O线程写入本地的中转日志（relay log）文件（与binlog文件一致） 从库SQL线程读取relay log文件重放 传输文件格式 # 通过上图可以看见，主库会将binlog推送从库。 那么binlog是什么格式？\nbinlog的三种格式 # statement格式： 实际执行的sql语句 row格式，所有变更前后的数据（一个Table_map event , 一个 Delete_rows event） mixed格式： 默认选择statement格式，需要的时候该用row格式 优缺点 # 优点 缺点 statement statement传输数据少 删除语句带limit可能会存在走错索引，导致主库和从库删除的数据不一致 row（常用） 可以恢复数据，不会造成数据不一致 row传输数据可能会很多,比较占空间。 mixed 继承了statement的优点，屏蔽了row的缺点 不能恢复数据 趣味问答 如果使用now()函数插入数据，通过statement将数据同步到从库，会不会导致时间不一致？ 不会，mysql会增加一个set timestamp=xxxxx\n如果两个节点互为主备的模式下，会不会产生循环复制？ 不会，binlog里面会记录server_id， 如果binlog里的server_id和自己的server_id一致，则不执行。 主从模式下的高可用 # 主从延迟 # 什么情况下会造成主从延迟？\n从库机器性能差 从库读压力大 大事务 大表DDL 主从延迟了会有什么问题？\n主库更新了数据，从库查不到 主从延迟了怎么处理？\n主从延迟策略 # 可靠性优先策略 # 主库发现和从库存在延迟，先关闭写状态，等到延迟为0时，再开启从库写，然后将流量达到从库。 备注：图中的SBM，是seconds_behind_master参数的简写。\n判断备库B现在的seconds_behind_master，如果小于某个值（比如5秒）继续下一步，否则持续重试这一步； 把主库A改成只读状态，即把readonly设置为true； 判断备库B的seconds_behind_master的值，直到这个值变成0为止； 把备库B改成可读写状态，也就是把readonly 设置为false； 把业务请求切到备库B。 这个切换流程，一般是由专门的HA系统来完成的，我们暂时称之为可靠性优先流程。\n可用性优先策略 # 如果强行把步骤4、5调整到最开始执行，也就是说不等主备数据同步，直接把连接切到备库B，并且让备库B可以读写，那么系统几乎就没有不可用时间了。 我们把这个切换流程，暂时称作可用性优先流程。这个切换流程的代价，就是可能出现数据不一致的情况。\n从库并行复制 # 主从延迟的核心问题是从库执行relay log的效率追不上主库写入binlog的效率。那我们提升从库的执行relay log的能力是不是可以解决呢？ coordinator就是原来的sql_thread, 不过现在它不再直接更新数据了，只负责读取中转日志和分发事务。真正更新日志的，变成了worker线程。而work线程的个数，就是由参数slave_parallel_workers决定的。根据我的经验，把这个值设置为8~16之间最好（32核物理机的情况），毕竟备库还有可能要提供读查询，不能把CPU都吃光了。 但是对于事务来讲，要怎么分发给不同的线程执行呢？ 一个个事务分发？ 可能会导致后分发的事务先执行。 同一个事务发给不同的worker执行？ 先后顺序问题也会造成数据不一致。\n分发原则 # 不能造成更新覆盖。同一行的两个事务，必须分发到同一个worker中 同一个事务不能拆开，必须放到同一个worker中执行 分发策略 # 按表分发策略 很好理解，但是如果出现热点表就可能退化成了单线程复制了 按行分发策略 要解决热点表的并行复制问题，就需要一个按行并行复制的方案。按行复制的核心思路是：如果两个事务没有更新相同的行，它们在备库上可以并行执行。显然，这个模式要求binlog格式必须是row。 约束条件 这两个方案其实都有一些约束条件：\n要能够从binlog里面解析出表名、主键值和唯一索引的值。也就是说，主库的binlog格式必须是row； 表必须有主键； 不能有外键。表上如果有外键，级联更新的行不会记录在binlog中，这样冲突检测就不准确。 主从延迟业务解决方案 # 强制走主库方案； sleep方案； 判断主备无延迟方案； 配合semi-sync方案（等从库ack之后，主库的commit才算成功）； 等主库位点方案； 等GTID方案。 主库宕机，主备切换 # 先来看看互联网一主多从的玩法\n一主多从架构 # 图中，虚线箭头表示的是主备关系，也就是A和A’互为主备， 从库B、C、D指向的是主库A。一主多从的设置，一般用于读写分离，主库负责所有的写入和一部分读，其他的读请求则由从库分担。 如果这个时候A宕机了，怎么办？\n主备切换 # 基于位点的主备切换 # 当我们把节点B设置成节点A’的从库的时候，需要执行一条change master命令：\nCHANGE MASTER TO MASTER_HOST=$host_name MASTER_PORT=$port MASTER_USER=$user_name MASTER_PASSWORD=$password MASTER_LOG_FILE=$master_log_name MASTER_LOG_POS=$master_log_pos 这个位点很难精确取到，只能取一个大概位置。为什么这么说呢？ 考虑到切换过程中不能丢数据，所以我们找位点的时候，总是要找一个“稍微往前”的，然后再通过判断跳过那些在从库B上已经执行过的事务。 一种取同步位点的方法是这样的：\n等待新主库A’把中转日志（relay log）全部同步完成； 在A’上执行show master status命令，得到当前A’上最新的File 和 Position； 取原主库A故障的时刻T； 用mysqlbinlog工具解析A’的File，得到T时刻的位点。 如果A在宕机前把数据推送给了A’和B。那当A\u0026rsquo;切换成主库时，位点可能是最后一条数据的位点，但是B其实已经执行过了，在执行就会报错。所以需要忽略这些错误。\n基于GTID的主备切换 # GTID（Global Transaction Identifier，也就是全局事务ID）\nGTID=server_uuid:gno 其中：\nserver_uuid是一个实例第一次启动时自动生成的，是一个全局唯一的值； gno是一个整数，初始值是1，每次提交事务的时候分配给这个事务，并加1。 GTID模式下的切换主库的语法\nCHANGE MASTER TO MASTER_HOST=$host_name MASTER_PORT=$port MASTER_USER=$user_name MASTER_PASSWORD=$password master_auto_position=1 其中，master_auto_position=1就表示这个主备关系使用的是GTID协议。可以看到，前面让我们头疼不已的MASTER_LOG_FILE和MASTER_LOG_POS参数，已经不需要指定了。 我们把现在这个时刻，实例A’的GTID集合记为set_a，实例B的GTID集合记为set_b。接下来，我们就看看现在的主备切换逻辑。 我们在实例B上执行start slave命令，取binlog的逻辑是这样的：\n实例B指定主库A’，基于主备协议建立连接。 实例B把set_b发给主库A’。 实例A’算出set_a与set_b的差集，也就是所有存在于set_a，但是不存在于set_b的GITD的集合，判断A’本地是否包含了这个差集需要的所有binlog事务。 a. 如果不包含，表示A’已经把实例B需要的binlog给删掉了，直接返回错误； b. 如果确认全部包含，A’从自己的binlog文件里面，找出第一个不在set_b的事务，发给B； 之后就从这个事务开始，往后读文件，按顺序取binlog发给B去执行。 总结 # 本篇主要是剖析Mysql的主从同步。\n先从整体流程上看Mysql的同步过程。 然后从具体的数据格式分析。 接着分析主从的高可用，讲了两个核心问题，1是主从延迟，2是主备切换。 主从延迟有两种策略，可靠性和可用性策略。一种并行复制的解决方案 主备切换也有两种策略，位点和GTID ","date":"27 July 2022","permalink":"/posts/mysql%E4%B8%BB%E4%BB%8E%E5%90%8C%E6%AD%A5%E7%AB%9F%E7%84%B6%E8%BF%99%E4%B9%88%E5%A4%9A%E7%BB%86%E8%8A%82/","section":"","summary":"整体流程 # 主库发生数据变更，将数据写入到binlog文件中 从库I/O线程发起dump请求 主库I/O线程将指定位点的binlog推送到从库 从库I/O线程写入本地的中转日志（relay log）文件（与binlog文件一致） 从库SQL线程读取relay log文件重放 传输文件格式 # 通过上图可以看见，主库会将binlog推送从库。 那么binlog是什么格式？","title":"Mysql主从同步竟然这么多细节"},{"content":"","date":"27 July 2022","permalink":"/tags/","section":"Tags","summary":"","title":"Tags"},{"content":"","date":"20 June 2022","permalink":"/tags/spring/","section":"Tags","summary":"","title":"Spring"},{"content":"","date":"20 June 2022","permalink":"/categories/spring/","section":"Categories","summary":"","title":"Spring"},{"content":" 感觉好久没写过博客了，刚好最近遇到一个还挺有意思的问题，就记录一下吧。\n现象 # ??? Spring不是通过三级缓存解决了循环依赖问题吗？ 这不就是A依赖B，然后B依赖A吗？怎么也报循环依赖啊。\n问题排查 # 排查思路 # 难道这个版本的Spring没解决？写个Demo验证一下（简单写个TestService1和TestService2相互依赖就行）。启动很成功啊。【不过这里还有一个比较好玩的现象，就是在TestService1的方法上加上@Async注解，就会报循环依赖了，这个google上有很多答案，其实就是TestService1被代理了，引用变了，然后TestService2还保留的是原始的引用】 把相关依赖去掉试试（把ConnectServiceImpl和UserServiceImpl中的其他依赖去掉试试看了），还是报错循环依赖。 源码分析 # what\u0026rsquo;s the hell? 只能捋捋源码了。 看看Spring解决循环依赖的过程 当我发现初始化前后，这个ConnectService的引用不一样时，问题就已经浮出水面了。这个情况应该跟@Async的情况是一样的，就是UserService中注入了ConnectService的引用，然后后续ConnectService初始化的时候，被包装了，引用变了，然后ConnectService初始化会判断新的引用和旧的是否相同，如果不相同，会去找ConnectService实际上依赖的bean(userService)是否创建了，如果创建了就添加到依赖列表中，如果依赖列表不为空，就报错循环依赖。 那么问题来了，实例化的时候包装了ConnectService，引用变成新的了，但是正常来讲，不应该包装啊。 Test1和Test2相互引用也没有被包装啊。 那就来看看源码吧 可以看到，在初始化这个ConnectService类的时候，会调用一个applyBeanPostProcessorsAfterInitialization方法，这个方法的会应用所有的beanPostProcessor，其中有一个方法参数校验的beanPostProcessor会代理这个类。所以导致引用变了。 那罪魁祸首就出来了呀，就是这个MethodValidationPostProcessor会代理这个bean，然后修改引用。那为啥会被这个MethodValidationPostProcessor代理呢。当然是这个AOP啦。 解决 # 两种方案 # 去除@Validated校验。 注入UserService时加上@Lazy注解 方案一得加好多校验代码，选择方案二吧。\n总结 # 循环依赖处理失效的场景 # 初始化过程生成了新的代理对象（一般应该是初始化过程中使用了一些前后置处理器） 使用@DependOn产生循环依赖 非单例产生循环依赖 虽然2，3在本案例中并没有提到，但是应该也是可以明白的\n参考 # https://zhuanlan.zhihu.com/p/344624139 （三级缓存分析的还比较清晰）\n","date":"20 June 2022","permalink":"/posts/spring%E7%9C%9F%E7%9A%84%E5%AE%8C%E5%85%A8%E8%A7%A3%E5%86%B3%E4%BA%86%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96%E5%90%97/","section":"","summary":"感觉好久没写过博客了，刚好最近遇到一个还挺有意思的问题，就记录一下吧。","title":"Spring真的完全解决了循环依赖吗"},{"content":"","date":"20 June 2022","permalink":"/tags/%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/","section":"Tags","summary":"","title":"问题排查"},{"content":"","date":"27 April 2022","permalink":"/tags/redis/","section":"Tags","summary":"","title":"Redis"},{"content":"","date":"27 April 2022","permalink":"/categories/redis/","section":"Categories","summary":"","title":"Redis"},{"content":" 认识分布式锁 # Distributed locks are a very useful primitive in many environments where different processes must operate with shared resources in a mutually exclusive way. 分布式锁是在分布式环境中保证不同的进程以相互独立的方式操作共享资源的一种实现方式。（说白了，分布式锁就是在分布式环境下实现进程同步操作共享资源的方式） 和本地锁（synchronized,reentrantlock）相比，分布式锁有什么不一样的地方呢？ 场景不同，分布式场景。\n分布式锁特性 # 安全性：相互独立，任何情况下，只能有一个客户端持有锁 死锁释放：即使持有锁的客户端宕机了，其他客户端最终总能获取锁。 容错性：只要大多数的Redis节点无故障，客户端总能获取锁和释放锁。 分布式锁的实现原理 # 锁主要需要解决的问题\n互斥访问 死锁问题 可重入 阻塞等待 Redis分布式锁是怎么做的呢？ 其实就一条语句 SET resource_name my_random_value NX PX 30000 当客户端需要获取锁时，就往redis发送上面的语句，如果resource_name这个key已经存在了，就无法插入到redis中，也就无法获取锁。 如果没有，就将 resource_name -\u0026gt; my_random_value 设置到redis中。当其他客户端也想访问该资源时，就不能访问了，这就解决了互斥访问问题。 那客户端在处理业务的情况下宕机了怎么办，由于redis自带的失效时间处理，就很好的解决了死锁问题。 那客户端获取到了锁，在执行业务的时候，又有个地方要获取该资源的锁，怎么办呢？我们可以看看redission是怎么处理的。 那如果客户端没获取到锁，想一直等待锁呢？\n可能遇到的问题 1.执行过程中，锁的失效时间到期了怎么办？redission设置了一个定时器，每到失效时间的1/3，如果业务还没执行完，就刷新失效时间。 2.为什么要设置唯一的value？防止别人误解锁。设置唯一的value，只有加锁的人才能解锁。 3.设置过程中master节点宕机了怎么办？\nRedisson实现分布式锁源码分析 # redission分布式锁的使用 1.引入依赖 org.redisson redisson 3.13.5 2.配置 单机配置 config.useSingleServers().addAdress(\u0026ldquo;redis://127.0.0.1:6379\u0026rdquo;); 集群配置 config.useClusterServers().addAdress(\u0026ldquo;redis://127.0.0.1:6379\u0026rdquo;).addAdress(\u0026ldquo;redis://127.0.0.1:6380\u0026rdquo;); 3.使用 RLock lock = redissionClient.getLock(random_key); lock.lock(); lock.unLock();\n过程分析 加锁 解锁\nRedisson架构 # RedLock算法分析 # 现在我们大概了解了一下redission的分布式锁实现，那么在集群模式下会不会有什么问题呢？ 设想一个场景：\n客户端A从master获取到锁 在master将锁同步到slave之前，master宕掉了 slave节点被晋级为master节点 客户端B取得了同一个资源被客户端A已经获取到的另外一个锁。安全失效！ 这个问题如何处理呢？\nRedLock算法 我们假设有5个Redis master节点，这是一个比较合理的设置，所以我们需要在5台机器上面或者5台虚拟机上面运行这些实例，这样保证他们不会同时都宕掉。 为了取到锁，客户端应该执行以下操作:\n获取当前Unix时间，以毫秒为单位。 依次尝试从N个实例，使用相同的key和随机值获取锁。在步骤2，当向Redis设置锁时,客户端应该设置一个网络连接和响应超时时间，这个超时时间应该小于锁的失效时间。例如你的锁自动失效时间为10秒，则超时时间应该在5-50毫秒之间。这样可以避免服务器端Redis已经挂掉的情况下，客户端还在死死地等待响应结果。如果服务器端没有在规定时间内响应，客户端应该尽快尝试另外一个Redis实例。 客户端使用当前时间减去开始获取锁时间（步骤1记录的时间）就得到获取锁使用的时间。当且仅当从大多数（这里是3个节点）的Redis节点都取到锁，并且使用的时间小于锁失效时间时，锁才算获取成功。 如果取到了锁，key的真正有效时间等于有效时间减去获取锁所使用的时间（步骤3计算的结果）。 如果因为某些原因，获取锁失败（_没有_在至少N/2+1个Redis实例取到锁或者取锁时间已经超过了有效时间），客户端应该在所有的Redis实例上进行解锁（即便某些Redis实例根本就没有加锁成功）。 锁真正的有效时间：MIN_VALIDITY = TTL - (T2 - T1) - CLOCK_DRIFT . TTL：锁的失效时间 T1：第一个获取到锁的时间 T2: 最后一个获取到锁的时间 CLOCK_DRIFT:时钟漂移（每台计算机的时间可能不同，所以集群中不同节点的通信可能会产生时钟漂移),因为基本都是以客户端的时间频率进行前进的，所以时钟漂移基本可以忽略不计。\nredission中RedLock实现 但是有一个问题：这种操作不能保证每个锁都是发送到了不同的实例，如果所有的锁都在一个实例上，一样会遇到问题之前的问题。 于是，Redisson废弃了RedLock。Rlock的一些操作会直接同步到所有的slave节点。 然后我就跑去测试了一下，经测试： RLock操作会发送到每一个slave节点（Redisson只配master节点，slave节点也会收到）。\n","date":"27 April 2022","permalink":"/posts/redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/","section":"","summary":"认识分布式锁 # Distributed locks are a very useful primitive in many environments where different processes must operate with shared resources in a mutually exclusive way.","title":"Redis分布式锁"},{"content":"","date":"27 April 2022","permalink":"/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/","section":"Tags","summary":"","title":"分布式锁"},{"content":"","date":"19 April 2022","permalink":"/tags/java/","section":"Tags","summary":"","title":"Java"},{"content":"","date":"19 April 2022","permalink":"/categories/java/","section":"Categories","summary":"","title":"Java"},{"content":" What is fastthread.io? # 在线jstack thread dump分析工具。\nUse # jstack \u0026gt; thread.log 打开网址https://fastthread.io/ 将thread.log 上传到fastthread.io Menu # Exception # 存在正在抛异常的线程 https://blog.fastthread.io/2020/06/10/threads-throwing-exception/ Identical Stack trace # 具有相同堆栈跟踪的线程在此处分组。如果许多线程开始表现出相同的堆栈跟踪，这可能是一个问题. https://blog.fastthread.io/2016/02/22/thread-dump-analysis-pattern-repetitive-strain-injury-rsi/ 当应用程序出现性能瓶颈时，大部分线程将开始在有问题的瓶颈区域累积。这些线程将具有相同的堆栈跟踪。因此，每当大量线程表现出相同/重复的堆栈跟踪时，就应该调查这些堆栈跟踪。这可能表示性能问题\nCPU Thread # thread dump时刻，真正在使用cpu的thread。jvm的runable状态的线程不一定在消耗cpu。比如有些在进行IO的读写，并不消耗cpu。\nTransitive Graph (传递性图表) # 如果存在这个，说明可能有问题 Thread-A 可能已经获得了 lock-1，然后永远不会释放它。线程 B 可能已经获得了 lock-2 并等待这个 lock-1。Thread-C 可能正在等待获取 lock-2。这种线程之间的传递块可以使整个应用程序无响应。 https://blog.fastthread.io/2016/06/23/really-running/ (运动员模式)\nComplex DeadLock # 循环死锁 https://blog.fastthread.io/2016/05/18/circular-deadlock/ DeadLock # 死锁 https://blog.fastthread.io/2016/04/25/deadlock/ Finalizer Thread # 如果 finalizer 线程被 BLOCKED 或 WAITING 很长时间，它可能会导致 OutOfMemoryError。 https://blog.fastthread.io/2015/11/20/thread-dump-analysis-pattern-leprechaun-trap/ 具有 finalize() 方法的对象在垃圾收集过程中的处理方式与没有它们的对象不同。在垃圾回收阶段，带有 finalize() 的对象不会立即从内存中逐出。相反，作为第一步，这些对象被添加到 java.lang.ref.Finalizer 对象的内部队列中。有一个名为“ _Finalizer”_的低优先级 JVM 线程， 它执行队列中每个对象的 finalize() 方法。只有在 finalize() 方法执行后，对象才有资格进行垃圾回收。由于 finalize() 方法的糟糕实现，如果_Finalizer _线程被阻塞，那么它将对 JVM 产生严重的有害级联影响。\nFlame Graph # 火焰图(并不是指一段时间的各个线程占用cpu的时间，而是在线程dump时刻，统计有多少个线程在调用哪些方法，以此来生成的火焰图) https://blog.fastthread.io/2018/12/07/benefits-of-a-flame-graph/ 线程转储文件往往跨越数百行（有时数千行）。由于其冗长，很难构思和吸收线程转储中的所有信息。fastThread工具生成的火焰图将所有信息浓缩成一个单一的紧凑火焰图格式。它有助于您快速识别热代码路径。在本文中，让我们学习如何使用 fastThread 工具生成的火焰图进行有效的调试/故障排除。\nHere comes the question # 什么时候该去看thread dump log 呢? jvm gc？ java进程的cpu占用高？池化资源耗尽（数据库连接池，http调用池，dubbo）？ 怎么看哪些线程耗尽了数据库资源？\nSo How to grasp troubleshooting in thread dump # without thinking\n从exception找线索。 从Identical Stack trace中看看大多数线程都在干嘛。如果都在等外部连接，可能会有一些问题。 从DeadLock列看看有没有死锁。 for more，具体情况还是要具体分析。\n","date":"19 April 2022","permalink":"/posts/jstack%E5%88%86%E6%9E%90%E7%A5%9E%E5%99%A8/","section":"","summary":"What is fastthread.","title":"Jstack分析神器"},{"content":"","date":"19 April 2022","permalink":"/tags/jvm/","section":"Tags","summary":"","title":"JVM"},{"content":" 现象 # 容器每隔一段时候就会自动重启，大概一周左右。理由是OOMkilled。 查看jstack日志，发现里面竟有3319个线程在运行。 分析 # 看看这些线程都在做什么？（图表来源于fastthread.io） 可以看到有1578个pool，和1485个消费线程。而这里就占了90%。所以肯定有点问题。 于是就可以详细看pool和这个消费线程在做啥。 pool基本都是两个两个一组双数增长。而且也看不到什么业务代码。 消费线程也是两个两个的，一个上行，一个下行。 那只能从业务代码出发了。 从代码中搜索下行回复消息，找到了 根因 # 大致逻辑是，有个设备上下线的接口。\n每隔7分钟调用设备上线接口 触发iotClient的start(),里面会new IotMqttService() 然后触发线程池的创建，以及上下行消息的提交 触发两个监听两个阻塞队列读取上下行消息。 这就造成了线程数不断增长。最终导致超出容器分配的内存而被OOMkilled。\n修复 # 初始思路 设备下线时，触发线程池的关闭。梳理下线逻辑，在内部的一个clear方法，将线程池关掉。 但是写完，测试的时候发现线程数依旧在涨（这里在测试环境模拟了线上环境，然后通过脚本一直在跑请求），而且我明明都shutdownNow了，还是依旧会有消息线程的增长。 于是我在while(true)内部增加了中断处理。 但是神奇的是，线程数还是在涨。\n于是我在线程池关闭之后，通过一个异步线程打印当前程序的线程数依旧线程名称。发现消息线程确实会被处理掉，但是还是有这个pool-thread。那这个pool-thread是在哪里开启的呢？ �回到fastthread.io,看到这个pool-thread是通过ScheduledThreadPoo触发的。同样的，代码中大概率是通过newScheduledThreadPool创建的线程池，就搜一下，果然发现了这个。 不啰嗦了，这个的原因是：创建这个IotMqttService的时候也会初始化一个日志打印的线程池，也会有两个线程在做日志打印的工作。 于是我把这个改成了单例模式。 到这里，基本上才算清晰， 为啥线程池的shutdownNow不生效？(没有做break处理，shutdownNow只会将正在执行的线程进行中断，而业务上的线程在死循环等待，中断之后又进入了循环) 为啥pool-thread总是双数增长？（消费线程也是个线程池，之后业务设置了名称为消费线程，不然也是pool）\n最终成效 # 异步打印程序的线程结果 开了一个watch命令，没20s跑一次请求，跑了一下午，线程数基本都是稳定在105.\n总结 # 线程不断增长问题排查过程总结\ntop -Hp 查看cpu情况和线程情况 jstack \u0026raquo; jstack.log 分析jstack日志（通过fastthread.io分析） 通过fastthread.io的线程分组查看线程详情。 通过关键词定位业务逻辑。 分析业务逻辑，复现\u0026amp;解决问题 注意⚠️ 线程池使用还是要谨慎啊，千万要注意关闭的问题。\n遗留待处理问题 # 一个线程占用多少内存？【1.9g的容器内存，大概可以开启9900多个线程，加上堆内存之类的，一个线程大概几百kb】【csdn上有个人说大概100k，看起来还算可信。https://blog.csdn.net/spytian/article/details/113637759】 如果操作系统内存足够，一个Java程序可以无限增加线程吗？【应该会受JVM堆外内存限制，但是具体堆外内存是多少，怎么设置，我也还不太清楚】\n","date":"19 April 2022","permalink":"/posts/jstack%E5%AE%9E%E8%B7%B5-%E7%BA%BF%E7%A8%8B%E6%97%A0%E9%99%90%E5%A2%9E%E9%95%BF%E5%AF%BC%E8%87%B4%E8%A2%AB%E5%AE%B9%E5%99%A8oomkilled/","section":"","summary":"现象 # 容器每隔一段时候就会自动重启，大概一周左右。理由是OOMkilled。 查看jstack日志，发现里面竟有3319个线程在运行。 分析 # 看看这些线程都在做什么？（图表来源于fastthread.","title":"Jstack实践-线程无限增长导致被容器OOMkilled"},{"content":" jstack是啥 # jstack是java虚拟机自带的一种堆栈跟踪工具，用于分析java线程的执行情况 jstack常用实践 # 死锁分析 cpu高负载分析 请求外部资源导致的长时间等待 jstack常用命令 # jstack Options -F 强制dump线程堆栈信息. 用于进程hung住， jstack 命令没有响应的情况 -m 同时打印java和本地(native)线程栈信息，m是mixed mode的简写 -l 打印锁的额外信息\n如何看懂jstack的dump结果 # 先来看一份dump结果abc.log 第一行（基本信息） # ** main ** 表示线程名称 daemon 表示线程是否是守护线程 prio 表示我们为线程设置的优先级 os_prio 表示的对应的操作系统线程的优先级，由于并不是所有的操作系统都支持线程优先级，所以可能会出现都置为0的情况 tid 表示java中为这个线程的id nid 表示这个线程对应的操作系统本地线程id的十六进制表示，每一个java线程都有一个对应的操作系统线程 **[id] **线程栈初始地址\n第二行（线程状态） # 第二行一般显示线程当前状态。一个Thread对象可以有多个状态，在java.lang.Thread.State中，总共定义六种状态： 1.NEW 线程刚刚被创建，也就是已经new过了，但是还没有调用start()方法，jstack命令不会列出处于此状态的线程信息 2.RUNNABLE RUNNABLE这个名字很具有欺骗性，很容易让人误以为处于这个状态的线程正在运行。事实上，这个状态只是表示，线程是可运行的。一个单核CPU在同一时刻，只能运行一个线程。 3.BLOCKED 线程处于阻塞状态，正在等待一个monitor lock。通常情况下，是因为本线程与其他线程共用了一个锁。其他在线程正在使用这个锁进入某个synchronized同步方法块或者方法，而本线程进入这个同步代码块也需要这个锁，最终导致本线程处于阻塞状态。 4.WAITING 无限期等待另一个线程执行特定操作 调用以下方法可能会导致一个线程处于等待状态：\nObject.wait 不指定超时时间 # java.lang.Thread.State: WAITING (on object monitor)\nThread.join with no timeout\nLockSupport.park #java.lang.Thread.State: WAITING (parking)\n例如：对于wait()方法，一个线程处于等待状态，通常是在等待其他线程完成某个操作。本线程调用某个对象的wait()方法，其他线程处于完成之后，调用同一个对象的notify或者notifyAll()方法。Object.wait()方法只能够在同步代码块中调用。调用了wait()方法后，会释放锁。\n5.TIMED_WAITING 有限期等待另一个线程执行特定操作 对于以下方法的调用，可能会导致线程处于这个状态：\nThread.sleep#java.lang.Thread.State: TIMED_WAITING (sleeping)``\nObject.wait 指定超时时间 #java.lang.Thread.State: TIMED_WAITING (on object monitor)\nThread.join with timeout\nLockSupport.parkNanos#java.lang.Thread.State: TIMED_WAITING (parking)``\nLockSupport.parkUntil#java.lang.Thread.State: TIMED_WAITING (parking)``\n6.TERMINATED 线程终止\n说明，对于** java.lang.Thread.State: WAITING (on object monitor)和java.lang.Thread.State: TIMED_WAITING (on object monitor)**，对于这两个状态，是因为调用了Object的wait方法(前者没有指定超时，后者指定了超时)，由于wait方法肯定要在syncronized代码中编写，因此肯定是如类似以下代码导致： synchronized(obj) { \u0026hellip;\u0026hellip;\u0026hellip; obj.wait(); \u0026hellip;\u0026hellip;.. } 因此通常的堆栈信息中，必然后一个lock标记，如下（来自上图的main线程）： \u0026ldquo;main\u0026rdquo; #1 prio=5 os_prio=0 tid=0x00007f160c009800 nid=0x43db9 waiting on condition [0x00007f161377a000]]\n不上图怎么理解？ # 既然讲到线程状态，就不得不提锁了，如果多个线程都都在抢占同一资源，不就会造成死锁了。所以也能通过jstack来分析死锁问题。但是我们先要懂java是怎么上锁的。\nMonitor监控锁 # 线程想要获取monitor,首先会进入Entry Set队列，它是Waiting Thread，线程状态是Waiting for monitor entry。 当某个线程成功获取对象的monitor后,进入Owner区域，它就是Active Thread。 如果线程调用了wait()方法，则会进入Wait Set队列，它会释放monitor锁，它也是Waiting Thread，线程状态in Object.wait() 如果其他线程调用 notify() / notifyAll() ，会唤醒Wait Set中的某个线程，该线程再次尝试获取monitor锁，成功即进入Owner区域。 For Example , 通过synchronized来举例。 当线程执行到下面的逻辑时，就会进入到Entry Set队列，如果此时没有人占用obj，就会进入到Owner区域，当在synchronized内部调用obj.wait();方法时，就会进入到Wait Set队列，让其他线程获取obj执行相关逻辑。等待其他线程调用obj.notify()或者 notifyAll()时，就有可能会唤醒该线程，然后重新进入到Owner区域。\nsynchronized(obj) { \u0026hellip;\u0026hellip;\u0026hellip; }\n第三行（调用堆栈） # 反应在dump时刻，线程的状态及调用堆栈。\n对于jstack做的ThreadDump的栈，可以反映如下信息 # 如果某个相同的call stack经常出现， 我们有80%的以上的理由确定这个代码存在性能问题（读网络的部分除外）； 如果相同的call stack出现在同一个线程上（tid）上， 我们很很大理由相信， 这段代码可能存在较多的循环或者死循环； 如果某call stack经常出现， 并且里面带有lock，请检查一下这个lock的产生的原因， 可能是全局lock造成了性能问题； 在一个不大压力的群集里（w\u0026lt;2）， 我们是很少拿到带有业务代码的stack的， 并且一般在一个完整stack中， 最多只有1-2业务代码的stack， 如果经常出现， 一定要检查代码， 是否出现性能问题。 如果你怀疑有dead lock问题， 那么请把所有的lock id找出来，看看是不是出现重复的lock id。 jstack分析工具 # 在线分析工具 https://fastthread.io/ http://spotify.github.io/threaddump-analyzer\n","date":"19 April 2022","permalink":"/posts/jstack-%E6%8A%93%E4%BD%8F%E6%91%B8%E9%B1%BC%E7%9A%84%E7%BA%BF%E7%A8%8B/","section":"","summary":"jstack是啥 # jstack是java虚拟机自带的一种堆栈跟踪工具，用于分析java线程的执行情况 jstack常用实践 # 死锁分析 cpu高负载分析 请求外部资源导致的长时间等待 jstack常用命令 # jstack Options -F 强制dump线程堆栈信息.","title":"Jstack-抓住摸鱼的线程"},{"content":" 启动参数 # java -XX:NativeMemoryTracking=detail -XX:MetaspaceSize=256M -XX:MaxMetaspaceSize=256M -XX:+AlwaysPreTouch -XX:ReservedCodeCacheSize=128m -XX:InitialCodeCacheSize=128m -Xss512k -Xmx1g -Xms1g -XX:+UseG1GC -XX:G1HeapRegionSize=4M -jar lib/helfy-1.0-SNAPSHOT.jar\n现象 # 程序启动一段时间，就会被自动kill掉。 分析 # 从上面的jstat -gcutil 现象来看，应该不是heap OOM，也不是 Metaspace OOM。 那可能是堆外内存OOM，怎么验证呢？ 通过top分析Java进程内存占用 当这个内存到了3.7g多的时候，程序就会被kill掉。 通过jmap -heap 104139 查看Java堆内存占用 我们也可以通过pmap来查看进程的内存占用。 pmap -x 104139 | tail -n 1 通过jmap和pmap可以发现，pmap的内存占用比jmap的堆配置总和还多。 而且pmap的RSS也一直在涨。\n解释一下这个RSS的含义，如下图。一般来讲共享库所占的内存应该不会很多 https://www.jianshu.com/p/3bab26d25d2e\n这里基本就能确定是堆外内存OOM了\n默认来讲，堆外内存大小=设置的堆内存大小-XX:Xmx，但是从top的结果来看，基本上在3.7多就被kill了。 堆内存设置的是1g，然后metaspace设置的好像是256m。那如果堆外内存是1g的话，感觉说不太通。 ​\n为什么会发生堆外内存OOM呢？看看线程到底在做什么 先top一把 top -H 打印所有线程的使用情况 ​\n这个 280376一直是用了88%的cpu，稳居榜首。 通过jstack看看它到底在干嘛（这里存在一个十进制转16进制的转换） jstack 280375 | grep \u0026lsquo;44738\u0026rsquo; -A 40 从业务代码可以看出，应该是这个one.helfy.SleepyBean里面一直调用springboot的方式去解压jar包。用的是Inflater这个类，一直在申请堆外内存。\n祖传命令 # # 观察GC情况 ps -afx | grep java | grep -v grep | awk \u0026#39;{print $1}\u0026#39; | xargs -I{} jstat -gcutil {} 1s # 从JVM角度观察内存 jcmd \u0026lt;pid\u0026gt; VM.native_memory detail # 观察内存使用情况 pmap -x 1 # 排序一下内存占用 pmap -x 1 | sort -n -k3 # 跟踪系统调用（看谁在分配内存） strace -f -e \u0026#39;brk,mmap,munmap\u0026#39; -p \u0026lt;pid\u0026gt; 总结 # Top + jstack 分析cpu高负载场景 假设Java进程pid=60\ntop -H 60 ，找到一个pid=280376的高负载线程 printf %x 280376 | xargs -I {} sh -C \u0026ldquo;jstack 60 | grep {} -A 40\u0026rdquo; 参考 # https://tech.meituan.com/2019/01/03/spring-boot-native-memory-leak.html （案例来源） https://tech.meituan.com/2020/11/12/java-9-cms-gc.html （处理思路： 场景九）\n","date":"19 February 2022","permalink":"/posts/java%E5%A0%86%E5%A4%96%E5%86%85%E5%AD%98%E6%8E%92%E6%9F%A5/","section":"","summary":"启动参数 # java -XX:NativeMemoryTracking=detail -XX:MetaspaceSize=256M -XX:MaxMetaspaceSize=256M -XX:+AlwaysPreTouch -XX:ReservedCodeCacheSize=128m -XX:InitialCodeCacheSize=128m -Xss512k -Xmx1g -Xms1g -XX:+UseG1GC -XX:G1HeapRegionSize=4M -jar lib/helfy-1.","title":"Java堆外内存排查"},{"content":"","date":"13 February 2022","permalink":"/tags/java-mysql/","section":"Tags","summary":"","title":"java-mysql"},{"content":" 现象 # 生产数据库设置了数据库的字符集为utf8mb4。数据库层面可以正常插入表情。但是在java程序中设置表情却不生效。 测试数据库也设置了数据库的字符集为utf8mb4。数据库层面可以正常插入表情。但是在java程序中也可以正常插入表情。 测试和生产环境的区别是：测试环境数据库重启过。生产没有==。 但是生产环境重启数据库影响太大，不太现实。 有没有什么其他的解决方案呢？请往下看。\n先说结论，三种解决方案 # 重启数据库（character-set-server 这个配置只在数据库启动时生效） 修改连接配置，指定连接的字符集 （数据库连接后面加上 com.mysql.jdbc.faultInjection.serverCharsetIndex=45） 升级 mysql连接驱动到5.1.47之后的版本（因为这个版本之后设置encoding=utf8会自动映射成utf8mb4） 上个链接吧，完美解决。 https://blog.arstercz.com/mysql-connector-java-%E6%8F%92%E5%85%A5-utf8mb4-%E5%AD%97%E7%AC%A6%E5%A4%B1%E8%B4%A5%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%E5%88%86%E6%9E%90/ 作者的思路很清晰。\n对于修改连接配置这一点，有点奇怪的是， 我在本地连接数据库测试的时候，默认设置的字符集就是utf8mb4。 但是在预发环境抓连接mysql的包是，发现设置的字符集却是utf8。 上图！ 但是代码一样的呀！没有理由会有不同啊。 于是开始了下面的探索，嘿嘿嘿。\njava-mysql-connector和mysql建立连接的过程 # Mysql握手协议包 # java-mysql-connector设置字符集过程 # ### 一条SQL从客户端到服务器 详情建议阅读《高性能Mysql》第7.9章。\n顺带又了解一些Mysql的字符集相关内容 # 1.字符集参数含义 2.mysql字符集相关sql\nSQL 含义 SET NAMES utf8mb4 设置本次连接的字符集为utf8mb4 SELECT * FROM information_schema.COLLATIONS ; 查看mysql排序规则 show variables like \u0026lsquo;%character%\u0026rsquo;; 查看数据库字符集 show variables like \u0026lsquo;collation%\u0026rsquo;; 查看数据库排序规则 alter database 库名 default character set utf8mb4; 修改数据库字符集(character_set_database) set character_set_server=utf8; 设置服务器编码(character_set_server) java-mysql-connector源码（简单记录一下，方便以后回顾） # 主要是从类 ConnectionImpl 里面的 方法 configureClientCharacterSet 入手去追溯一下过程。 简单贴几个过程吧 初始设置字符集， 处理utf8和utf8mb4, 简单总结一下 # mysql连接过程【看上图】 mysql设置字符集过程【看上图】 mysql字符集应该注意的问题\n配置生效问题【有些配置可能要重启mysql服务器才能生效】 配置设置问题【java启动参数，环境变量，配置文件】 排查思路\n对比现象【代码相同，开发和预发建立连接时，设置的字符集不同】 猜想问题【服务器返回结果不同，导致设置的字符集不同】 分析过程，验证猜想【从抓包分析，设置字符集前，先获取了一波服务器配置，对比分析配置。发现差不多，没什么不同】 根据现象，分析过程【既然是字符集设置不同，就看它字符集设置的过程。最终发现问题】 发现问题，寻找解决方案【修改字符集配置】 ","date":"13 February 2022","permalink":"/posts/java%E8%BF%9E%E6%8E%A5mysql%E5%AD%97%E7%AC%A6%E9%9B%86%E8%AE%BE%E7%BD%AE%E8%BF%87%E7%A8%8B%E8%AF%A6%E8%A7%A3/","section":"","summary":"现象 # 生产数据库设置了数据库的字符集为utf8mb4。数据库层面可以正常插入表情。但是在java程序中设置表情却不生效。 测试数据库也设置了数据库的字符集为utf8mb4。数据库层面可以正常插入表情。但是在java程序中也可以正常插入表情。 测试和生产环境的区别是：测试环境数据库重启过。生产没有==。 但是生产环境重启数据库影响太大，不太现实。 有没有什么其他的解决方案呢？请往下看。","title":"Java连接Mysql字符集设置过程详解"},{"content":"","date":"13 February 2022","permalink":"/tags/utf8mb4/","section":"Tags","summary":"","title":"utf8mb4"},{"content":" 从mybatis日志中获取sql语句，通过explain进行分析。 # grep -E \u0026#39;==\u0026gt; Preparing:\u0026#39; bytello.log | sed \u0026#39;s/.*==\u0026gt; Preparing:/explain/\u0026#39; | sed \u0026#39;s/\\($\\)/;/\u0026#39; | sed \u0026#39;s/\\?/\u0026#34;\u0026#34;/g\u0026#39; | sed \u0026#39;s/LIMIT \u0026#34;\u0026#34;/LIMIT 5/\u0026#39; | sort -u | uniq \u0026gt; test.txt 稍微解释一下，怕以后忘了。 grep -E \u0026lsquo;==\u0026gt; Preparing:\u0026rsquo; bytello.log 是通过正则匹配包含\u0026rsquo;==\u0026gt; Preparing:\u0026lsquo;的行。 然后通过管道将每一行的结果输出到下一个命令。 sed \u0026rsquo;s/.==\u0026gt; Preparing:/explain/\u0026rsquo; 是将.==\u0026gt; Preparing替换成expalin。（熟悉一下sed的语法就行） 后面的sed含义类似。 sort -u | uniq 是去除重复行。 最后输出到test.txt # explain type含义 # system：系统表，少量数据，往往不需要进行磁盘IO const：常量连接 eq_ref：主键索引(primary key)或者非空唯一索引(unique not null)等值扫描 ref：非主键非唯一索引等值扫描 range：范围扫描 index：索引树扫描 ALL：全表扫描(full table scan) explain确实可以分析，但是sql太多了，难道一行一行看嘛。我们可是程序员。不能干这种事吧。 应该会有一些工具帮助我们做这些事的。\n通过慢查询日志分析 # 查看数据库是否开启慢查询，以及慢查询日志存放位置。 # show variables like \u0026lsquo;%slow_query_log%\u0026rsquo;;\nslow_query_log //是否开启，默认关闭，建议调优时才开启 slow_query_log_file //慢查询日志存放目录 开启慢查询 # set global slow_query_log = on;\n查询慢查询时间，默认是10s，但是测试推荐设置0。因为代价不高，然后方便分析。 # **show **variables **like **\u0026rsquo;%long_query_time%\u0026rsquo;;\n慢查询测试 select sleep(11);\n慢查询分析工具 # mysqldumpslow （mysql自带） # 常用命令\n得到返回记录集最多的10条SQL： mysqldumpslow -s r -t 10 /var/lib/mysql/mysql-slow.log 得到访问次数最多的10条SQL： mysqldumpslow -s r -t 10 /var/lib/mysql/mysql-slow.log 得到按照时间排序的前10条里面含有左连接的SQL： mysqldumpslow -s t -t 10 -g \u0026#34;left join\u0026#34; /var/lib/mysql/mysql-slow.log 也支持管道符命令 mysqldumpslow -s t -t 10 -g \u0026#34;left join\u0026#34; /var/lib/mysql/mysql-slow.log | more //分页显示 pt-query-digest （percona-toolkit中的产品） # 通过profilling来追踪具体的查询开销 # 查看profiling的开启状态。默认关闭。 show variables like \u0026#39;profiling\u0026#39;; 开启profiling set profiling = \u0026#39;ON\u0026#39;; 查询具体的查询开销 show profile; 为什么会慢 # 可以通过mysql-slow.log来查看sql具体的执行情况【记得开启slowlog】\n","date":"12 February 2022","permalink":"/posts/mysql%E6%85%A2%E6%9F%A5%E8%AF%A2%E5%88%86%E6%9E%90/","section":"","summary":"从mybatis日志中获取sql语句，通过explain进行分析。 # grep -E \u0026#39;==\u0026gt; Preparing:\u0026#39; bytello.","title":"Mysql慢查询分析"},{"content":" 先看一条社死SQL # SELECT*FROM t_device_online where device_id=8788 orderby start_time **desc limit **1;\n其中 device_id 没有索引， start_time有索引。表中数据量大概200w。这条语句执行平均耗时3s多。同时十几条这个请求。直接占住了数据库链接。导致后续请求调用都超时了。 200w数据查一条数据要花这么久吗？device_id 没有索引，全表扫描可能需要是吧。 但是我们通过执行计划分析，发现它走了start_time的联合索引。 好，我们去掉 orderby start_time desc 试试，结果只花了600ms。？ 索引比全表扫描还慢？ 去掉 where device_id=8788 试试，也就 不到 10ms。 ？ 这里涉及到两个知识点，一是索引，二是排序。\n索引排序详解 # 索引的存储方式 # 主键索引 联合索引 索引排序查询执行过程分析 # 一次查询最多只会用到一个索引，所以可能存在下面几种情况\nwhere走索引 order by 走索引 where和order by都走索引 where和order by都不走索引 表结构 # where走索引案例 # SELECT * **FROM **test_online **where **start_time \u0026gt; 1609842103 **order by **device_id desc; 【索引值start_time】 执行过程：\n走索引过程找出 start_time \u0026gt; 1609842103 的 rowid（默认是主键id） 将符合条件的rowid和排序字段（device_id）放入到排序缓存区中排序。 然后在根据排序好的rowid去查询row记录。 order by走索引案例 # order by走索引的情况特别坑，如果走错了索引，效率比全表扫描还慢的多，而且，加上limit还会帮你加上索引。这里就能解释上面的社死SQL问题了。\nSELECT * **FROM **test_online **where **device_id=10060 **order by **start_time **desc **; SELECT * **FROM **test_online **where **device_id=10060 **order by **start_time desc limit 0,20; 执行过程(不加limit)：\n全部扫描找到 device_id=10060 的 rowid（全表顺序扫描）。 将符合条件的rowid和排序字段（start_time）放入到排序缓存区中排序 然后在根据排序好的rowid去查询row记录（回表查） 执行过程（加上limit）：\n先根据order by的索引去查询符合where条件的数据；（相当于是走一个无效的索引去查找值，就是随机查找了，效率自然慢） 将符合条件的rowid和排序字段（start_time）放入到排序缓存区中排序 然后在根据排序好的rowid去查询row记录 有些博客讲这个慢在第三步，但是我想不通， 1.通过主键id回表应该也不至于很慢，而且mysql也有优化，数据量小的情况下，就会将所有的数据在排序缓存区中处理，不需要二次回表。 2.无法解释上面的情况，两次查询数据都为null，但是耗时差距却这么大。\n​\n​\nwhere和order by都走索引 # 执行过程：\n通过索引去过滤where条件的数据 将符合条件的rowid和排序字段放入到排序缓存区中排序 根据排序好的rowid查询row记录 ​\nwhere和order by都不走索引 # 执行过程：\n全表扫描where条件的数据 将符合条件的rowid和排序字段放入到排序缓存区中排序 根据排序好的rowid查询row记录 filesort # 我们注意到order by走索引不加limit和加limit的两种情况下，他们的explain最后一列，走全表扫描的有use filesort，另一个没有。 在我们的认知中，使用文件排序肯定比没有使用文件排序要快对吧，比较磁盘IO肯定更耗时嘛。 但是这里却相反了。当然现在我们知道了，是因为它走错了索引，导致了非常多无效的随机IO。 但是我们也可以了解一下这个filesort。 filesort不一定就会在文件中排序，\nfilesort is not always bad and it does not mean that a file is saved on disk. If the size of the data is small, it is performed in memory.\n按排序方式分为：\n数据量小时，在内存中快排 数据量大时，在内存中分块快排，再在磁盘上将各个块做归并 上面在分析排序过程时，排序完都会回表查询row记录，但是这个不一定是这样，也可以直接将行记录全查询出来在去排序，所以排序按回表次数又可以分为：\n两次传输排序（只将rowid和排序字段放入排序缓存区，然后在回表查询） 单次传输排序（直接将要查询的行数据放入排序缓存区排序，排序完直接返回，避免二次随机回表查询） 我们知道随机回表的效率肯定比顺序IO慢，所以在mysql4.1之后的版本中，mysql优化了这个排序， MySQL做了以下限制：\n所有需要的列或ORDER BY的列只要是BLOB或者TEXT类型，则使用两次传输排序。 所有需要的列和ORDER BY的列总大小超过max_length_for_sort_data字节，则使用两次传输排序。 总结 # 走索引不一定比全表扫描快，还得看你索引用的对不对，order by用索引where不用索引就是血淋淋的教训。 mysql会帮你优化查询，但是优化不一定是最好的，比如本来查询走全表扫描才几百ms，但这个limit觉得才查几条数据，走索引肯定更快，结果这个索引反而更慢了。 use filesort不一定就是使用文件排序，得看数据量大不大。也不一定会两次回表，看你列的数据多不多。 参考 # https://segmentfault.com/a/1190000015987895 https://petrunia.net/2007/08/29/how-mysql-executes-order-by/ (order by 执行过程详解) https://dev.mysql.com/doc/refman/5.7/en/order-by-optimization.html#order-by-optimizer-control (mysql order by) https://dev.mysql.com/doc/refman/5.7/en/limit-optimization.html (mysql limit)\n","date":"10 February 2022","permalink":"/posts/orderby%E8%B8%A9%E5%9D%91%E4%B9%8B%E8%B7%AF/","section":"","summary":"先看一条社死SQL # SELECT*FROM t_device_online where device_id=8788 orderby start_time **desc limit **1;","title":"OrderBy踩坑之路"},{"content":" 查看业务日志 # 查看死锁日志 # show engine innodb status; （查询语句）\n------------------------ LATEST DETECTED DEADLOCK ------------------------ 2022-01-12 08:24:23 0x7f5a5cf75700 *** (1) TRANSACTION: //事务A TRANSACTION 9400396, ACTIVE 0 sec inserting mysql tables in use 1, locked 1 LOCK WAIT 3 lock struct(s), heap size 1136, 2 row lock(s), undo log entries 10 MySQL thread id 2138935, OS thread handle 140026474653440, query id 58338774 10.21.17.247 liuchuangzhao update insert into t_device_online (device_id, start_time, end_time,online_times) values (133, 1641975738, 1641975861,1) , (137, 1641975727, 1641975861,1) , (138, 1641975743, null,1) , (144, 1641975726, null,1) , (146, 1641975742, null,1) , (147, 1641975728, 1641975862,1) , (150, 1641975724, null,1) , (152, 1641975746, 1641975861,1) , (154, 1641975744, null,1) , (28, 1641975737, 1641975861,1) , (158, 1641975744, null,1) , (32, 1641975736, 1641975862,1) , (162, 1641975733, null,1) , (36, 1641975736, 1641975861,1) , (168, 1641975729, null,1) , (40, 1641975732, n *** (1) WAITING FOR THIS LOCK TO BE GRANTED: RECORD LOCKS space id 61 page no 30559 n bits 824 index device_id of table `ifp_remote_platform`.`t_device_online` trx id 9400396 lock_mode X locks gap before rec insert intention waiting *** (2) TRANSACTION: //事务B TRANSACTION 9400297, ACTIVE 1 sec fetching rows mysql tables in use 1, locked 1 72 lock struct(s), heap size 24784, 1748 row lock(s), undo log entries 5 MySQL thread id 2138649, OS thread handle 140026083497728, query id 58338328 10.21.17.247 liuchuangzhao updating delete from t_device_online where end_time is null and device_id in ( 133 , 137 , 138 , 144 , 146 , 147 , 150 , 152 , 154 , 28 , 158 , 32 , 162 , 36 , 168 , 40 , 10536 , 169 , 170 , 42 , 10411 , 171 , 172 *** (2) HOLDS THE LOCK(S): RECORD LOCKS space id 61 page no 30559 n bits 824 index device_id of table `ifp_remote_platform`.`t_device_online` trx id 9400297 lock_mode X locks gap before rec *** (2) WAITING FOR THIS LOCK TO BE GRANTED: RECORD LOCKS space id 61 page no 30545 n bits 672 index device_id of table `ifp_remote_platform`.`t_device_online` trx id 9400297 lock_mode X waiting *** WE ROLL BACK TRANSACTION (1) 事务A（insert） 事务B（delete） ​ 持有行锁 824 index（X锁） 等行锁 824 index（X锁） 等行锁 672 index（X锁） 回滚 从死锁日志上，可以，事务A并没有持有事务B所需要的资源啊，但是从现象上来看，事务A应该是持有了672的行锁。那我们就必须先了解insert的加锁过程。\ninsert加锁 # insert加锁过程 # 先加插入意向Gap锁(insert intention gap lock)【如果别的事务已经有了这个间隙的锁Gap Lock，就无法加insert intention gap lock】 然后对插入的记录加索引记录锁（index-record lock）不会加gap锁，不影响其他insert的执行，除非他们插入的记录的索引值相同。 如果插入的记录索引值相同，则会出现duplicate-key error，就会对改索引加一个共享锁（shared lock）。但是如果有多个请求同时插入同一个索引值，这种情况可能会出现死锁。 举个例子：\n事务A 事务B 事务C START TRANSACTION; ​ ​ INSERT INTO t1 VALUES(1); START TRANSACTION; START TRANSACTION; 获取到index-record lock(也是这个行记录的排查锁) INSERT INTO t1 VALUES(1); INSERT INTO t1 VALUES(1); 增加shared lock 遇到duplicate-key error 遇到duplicate-key error ​ 等待shared lock 等待shared lock ROLLBACK; ​ ​ 释放shared lock 获取到shared lock 获取到shared lock 释放排查锁 等待排查锁 等待排查锁 死锁 死锁 事务B和C都获取到了shared lock，都在等待排他锁，但是排他锁和shared lock互斥，所以事务B和C都获取不到排他锁。（想要获取排他锁必须等对方释放shared lock，但是这是不可能的） 还有一种情况也会产生死锁\n事务A 事务B 事务C START TRANSACTION; ​ ​ delete from t1 where id = 1; START TRANSACTION; START TRANSACTION; 获取到index-record lock(也是这个行记录的排查锁) INSERT INTO t1 VALUES(1); INSERT INTO t1 VALUES(1); 增加shared lock 遇到duplicate-key error 遇到duplicate-key error ​ 等待shared lock 等待shared lock commit; ​ ​ 释放shared lock 获取到shared lock 获取到shared lock 释放排查锁 等待排查锁 等待排查锁 死锁 死锁 结论 # 三个以上的并发插入，如果一个回滚了，可能会存在死锁（原因是出现duplicate-key error，其他事务都获取不到排他锁**）** 一个删除，两个并发插入，删除提交后也会造成死锁。 ​\nDelete加锁 # delete加锁过程\n设置一个next-key的排他锁在每个搜索的行记录。（意味着除了占住行锁，还会占住间隙锁） 对于使用唯一索引搜索的情况只会对搜索的行加索引记录锁 复现 # 复现方式1 执行步骤：\n事务A 事务B 开始事务 开始事务 插入133 删除137 插入137 提交 死锁 死锁日志\n------------------------ LATEST DETECTED DEADLOCK ------------------------ 2022-01-19 12:38:16 0x7f59772d9700 *** (1) TRANSACTION: //事务A TRANSACTION 10649448, ACTIVE 136 sec inserting mysql tables in use 1, locked 1 LOCK WAIT 3 lock struct(s), heap size 1136, 2 row lock(s), undo log entries 2 MySQL thread id 2419529, OS thread handle 140026471950080, query id 66144333 10.21.17.247 liuchuangzhao update /* ApplicationName=DBeaver 21.0.0 - SQLEditor \u0026lt;dev_with_high_pri.sql\u0026gt; */ insert into t_device_online (device_id, start_time, end_time,online_times) values(137, 1641975727, 1641975861,1) *** (1) WAITING FOR THIS LOCK TO BE GRANTED: RECORD LOCKS space id 61 page no 30554 n bits 824 index device_id of table `ifp_remote_platform`.`t_device_online` trx id 10649448 lock_mode X locks gap before rec insert intention waiting *** (2) TRANSACTION: //事务B TRANSACTION 10649665, ACTIVE 28 sec fetching rows mysql tables in use 1, locked 1 35 lock struct(s), heap size 8400, 203 row lock(s), undo log entries 100 MySQL thread id 2419581, OS thread handle 140022228293376, query id 66144549 10.21.17.247 liuchuangzhao updating /* ApplicationName=DBeaver 21.0.0 - SQLEditor \u0026lt;Script-4.sql\u0026gt; */ delete from t_device_online where device_id in (133) *** (2) HOLDS THE LOCK(S): RECORD LOCKS space id 61 page no 30554 n bits 824 index device_id of table `ifp_remote_platform`.`t_device_online` trx id 10649665 lock_mode X locks gap before rec *** (2) WAITING FOR THIS LOCK TO BE GRANTED: RECORD LOCKS space id 61 page no 30545 n bits 712 index device_id of table `ifp_remote_platform`.`t_device_online` trx id 10649665 lock_mode X waiting *** WE ROLL BACK TRANSACTION (1) 复现方式2 执行过程\n事务A 事务B 开始事务 开始事务 插入137 删除137,133 插入133 死锁 ​ ​ 死锁日志\n------------------------ LATEST DETECTED DEADLOCK ------------------------ 2022-01-19 12:58:59 0x7f5a74376700 *** (1) TRANSACTION: //事务A TRANSACTION 10652218, ACTIVE 4 sec starting index read mysql tables in use 1, locked 1 LOCK WAIT 5 lock struct(s), heap size 1136, 5 row lock(s), undo log entries 1 MySQL thread id 2420044, OS thread handle 140022237755136, query id 66160375 10.21.17.247 liuchuangzhao updating /* ApplicationName=DBeaver 21.0.0 - SQLEditor \u0026lt;Script-4.sql\u0026gt; */ delete from t_device_online where device_id in (137,133) *** (1) WAITING FOR THIS LOCK TO BE GRANTED: RECORD LOCKS space id 61 page no 30554 n bits 824 index device_id of table `ifp_remote_platform`.`t_device_online` trx id 10652218 lock_mode X waiting *** (2) TRANSACTION: //事务B TRANSACTION 10652205, ACTIVE 10 sec inserting mysql tables in use 1, locked 1 3 lock struct(s), heap size 1136, 2 row lock(s), undo log entries 2 MySQL thread id 2420043, OS thread handle 140026473572096, query id 66160420 10.21.17.247 liuchuangzhao update /* ApplicationName=DBeaver 21.0.0 - SQLEditor \u0026lt;dev_with_high_pri.sql\u0026gt; */ insert into t_device_online (device_id, start_time, end_time,online_times) values (133, 1641975727, 1641975861,1) *** (2) HOLDS THE LOCK(S): RECORD LOCKS space id 61 page no 30554 n bits 824 index device_id of table `ifp_remote_platform`.`t_device_online` trx id 10652205 lock_mode X locks rec but not gap *** (2) WAITING FOR THIS LOCK TO BE GRANTED: RECORD LOCKS space id 61 page no 30545 n bits 712 index device_id of table `ifp_remote_platform`.`t_device_online` trx id 10652205 lock_mode X locks gap before rec insert intention waiting *** WE ROLL BACK TRANSACTION (2) 死锁原因分析 # 虽然复现方式不一样，但是死锁日志是一样的。\n复现1原因分析： # 事务A 事务B 开始事务 开始事务 插入133（插入index-recode-lock，意向排他锁，是一个隐式排他锁） 删除137（获取了137的行锁及周围间隙锁） ​ 删除133 （发现133有隐式排他锁，就帮他加上记录锁。 等待133的排他锁，也就是133的行锁） 插入137（等待137周围的间隙锁） ​ 死锁 复现2原因分析： # 事务A 事务B 开始事务 开始事务 插入137（插入index-recode-lock，意向排他锁，是一个隐式排他锁） 删除137,133 （获取了133的行锁，等待137的行锁）【这里可以说明删除会对in重排序，不然不会造成死锁】 插入133（等待133的行锁） 死锁 ​ ​ 业务死锁分析 # insert执行流程长，拿到了一些device_id insert执行过程中，delete 对 in 里面的device_id进行排序，然后先于insert拿到后面要执行的device_id，但是需要等待insert已经获取的device_id。 insert要等delete已获取的device_id 就死锁了 待验证 为什么delete会对in里面的device_id重排序？ 我觉得是因为删除语句没有走索引，要全表扫描，mysql为了避免随机IO，就对in的device_id排序了。 为什么insert 不会？ insert默认是通过主键id去查找，然后插入都是很快的，所以不需要重排序。 ​\n复现1和复现2和最开始的死锁日志一致。 如果复现1还不能说明问题的话，复现2就很能说明问题了。只要insert的够慢，delete 先拿到insert接下来要删除的行锁，就会死锁。 ​\n参考 # https://blog.csdn.net/varyall/article/details/80219459 (insert加锁分析) https://cloud.tencent.com/developer/article/1900240 (insert加锁分析) https://dev.mysql.com/doc/refman/5.7/en/innodb-locks-set.html （mysql官网innodb加锁说明） https://www.docs4dev.com/docs/zh/mysql/5.7/reference/innodb-locks-set.html(中文文档)\n","date":"10 February 2022","permalink":"/posts/mysql%E6%8F%92%E5%85%A5%E5%88%A0%E9%99%A4%E6%AD%BB%E9%94%81%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/","section":"","summary":"查看业务日志 # 查看死锁日志 # show engine innodb status; （查询语句）","title":"Mysql插入删除死锁问题排查"},{"content":"","date":"9 February 2022","permalink":"/tags/cache/","section":"Tags","summary":"","title":"Cache"},{"content":"","date":"9 February 2022","permalink":"/categories/cache/","section":"Categories","summary":"","title":"Cache"},{"content":" 概述 # 缓存是一件很复杂的事情。我认为比较核心的知识应该是，\n缓存一致性保证 缓存数据结构设计和缓存内存管理 缓存中间件的建设（包含通信设计，故障处理，高可用保障等一系列知识） 本文主要从使用的角度去剖析缓存中的一些核心的内容。 在使用上，我把缓存比较核心的东西总结为， 一个业务难题，缓存使用场景 一个核心问题，并发和异常的情况下，如何尽可能的保证数据的一致性。 两个核心操作，查询，更新； 业务难题 # 之前我们聊过一轮缓存相关的内容，我们之前一直纠结于要不要使用缓存，以及什么情况下该使用缓存。 这个业务难题，你很难去笼统的说，什么情况下该用缓存，什么情况下不该用缓存？ 我觉得我们只能根据缓存带来的优点和可能出现的问题然后在结合我们的业务场景去考虑，我们究竟要不要使用缓存。\n缓存优缺点 # 优点：\n快，提高响应速度和系统吞吐量 减轻数据库压力 缺点：\n数据一致性问题 增加系统的复杂性和维护成本 建议使用缓存的场景，\n读多写少 高频访问且耗时服务 不管是哪种场景，一旦我们决定在业务中使用缓存，有一个问题是不可避免的，就是如何保证数据的一致性。 我甚至有一个偏执的想法，就是，如果你能cover住缓存的可能带来的问题。那其实只要能带来性能上的提升，我们可以大胆的使用缓存。\n缓存更新探讨 # Cache Aside # ### 存在问题 脏数据 : 读请求先读数据库，然后写请求更新数据库，然后失效缓存，最后读请求在更新缓存（出现概率很低，但是如果是多个节点，某个节点很慢，确实会出现这个场景，但是，一般来讲，不同节点请求的数据应该是不同的）【加锁；lease；延时双删】 缓存击穿 ： 写请求失效缓存后，大量读请求访问数据库。【加锁，获取不到锁的请求尝试等一下在访问数据库；facebook采用lease的方式处理】 异常情况：写数据库成功，删缓存失败；【异步确保；分布式事务保证】 缓存脏数据图解\n带着上面的问题，我们先来看看facebook的lease设计 lease设计主要解决两个问题：\n过期设置（Cache Aside的脏数据问题） 大量频繁的读写请求，导致读总是查询数据库。 但是它有自己的客户端和服务器。为了方便理解，我这里沿用了上诉Cache Aside图。 这里先说明一下lease生成规则，\n当缓存中的key失效时，生成一个lease; 然后每10s更新lease并清除返回标识。 对于查询请求，缓存未命中时，将lease返回给客户端，然后清除该key的lease。 于是针对每个过期key，都会对应一个lease:key-value的缓存。 有兴趣的话，可以看看这篇文档 https://www.usenix.org/system/files/conference/nsdi13/nsdi13-final170_update.pdf ​\n解决缓存击穿\u0026amp;脏数据 # 1.数据库查询加锁 当然，还有一些保底手段去处理缓存不命中的问题。 比如，定时更新缓存数据。\n解决缓存雪崩 # 缓存雪崩与缓存击穿的最大的区别，就是 击穿是一个key或者少量key失效时，大量并发请求； 而缓存雪崩则是大量key同时失效。 引发这个问题的根本原因是，\nkey的设置时间相同；【失效时间设置加一个随机值】 缓存不可用；【缓存高可用建设，少量机器宕机；大量机器宕机之类的故障处理】 解决缓存穿透 # 根本原因：请求缓存中不存在的值。然后就请求就必须去数据库。 处理方案：\n接口校验； 缓存null值或无效值。 增加布隆过滤器。【就是去缓存拿数据之前，先去布隆过滤器里查询数据是不是存在；不存在就直接返回了】 ​\n其他方式 # 当然，这个Cache Aside还会有很多变种误导大家。有些说法让我一度也觉得没啥问题； 比如。\n先删缓存，再更新数据库【并发查询和更新，可能出现脏数据；缓存击穿；异常】【也有解决方案：延时双删】 更新数据库，再更新缓存【并发更新脏数据；异常】 更新缓存，再更新数据库【并发更新脏数据；异常】 这些也不一定是错的。我们可以辩证的去看待，他们都在努力的去解决一个问题，就是数据一致性的问题。 https://juejin.cn/post/6844904137654534158#heading-12这个博客分析的挺好的。 ​\nRead/Write Through # 存在问题 # 并发：更新请求处理时，读请求是否要被阻塞。 阻塞的话，更新数据库时，大量读请求阻塞。跟直接访问数据库的区别在哪呢。 不阻塞的话，获取的就不是最新的数据。如果更新数据库失败就会出现幻读。 或者引入版本管理。那开发的代价就很高了。 异常：更新数据库失败，出现幻读。 所以要花很大的代价去维护缓存和数据库的一致性，而且数据库表的数据不尽相同，这一点处理起来应该也很困难。\nWrite Behind Caching # 存在问题 # 并发：好像没啥问题 异常：更新数据库失败了，重试保证最终一致性。好像也没啥问题。 那这个异步处理的时机应该怎么维护才算合适呢？数据一设置马上就异步线程去同步数据库。 但是还有一个问题，可能会出现刚更新完缓存，服务器宕机了。然后数据库没更新，就会导致数据丢失。这个问题好像没办法解。 ​\n总结 # 所以，其实综合来看，Cache Aside的方式是代价最小的。这可能也是目前被广泛使用的原因吧。 如果对缓存带来的问题有相应的解决措施的话，其实，能提高性能的话，不必太过于纠结要不要使用缓存。 ​\n参考 # https://coolshell.cn/articles/17416.html （缓存更新套路） https://www.usenix.org/system/files/conference/nsdi13/nsdi13-final170_update.pdf （facebook缓存建设） https://juejin.cn/post/6844904137654534158#heading-12 （缓存博客） https://draveness.me/papers-segcache/ （如何提高缓存利用率）\n","date":"9 February 2022","permalink":"/posts/%E7%AB%99%E5%9C%A8%E4%BD%BF%E7%94%A8%E8%A7%92%E5%BA%A6%E7%9C%8B%E7%BC%93%E5%AD%98/","section":"","summary":"概述 # 缓存是一件很复杂的事情。我认为比较核心的知识应该是，","title":"站在使用角度看缓存"},{"content":" Redis的设计中，有一个被大家熟知的概念，就是在6.0之前，Redis是单线程模型，6.0之后才引入的多线程。 尽管如此，单线程模型下的redis依旧性能强劲。 所以今天，我们就来好好研究一下redis的线程通信模型。 单线程模型 # redis是2009推出的，在2019年才引入多线程模型。为什么呢？ 单线程\n简单可维护 避免线程上下文切换开销 避免同步开销 大体上，Redis的单线程模型是标准的Reador模式，基于I/O多路复用实现的，一个统一的事件循环处理器去接受事件，然后分派到不同的处理器去处理。\n服务器启动流程图 # 详细图解 存在问题 # 单线程应该最怕一个问题，就是阻塞。有些操作就是要阻塞进行的，比如删除。\n看看作者是怎么想的 http://antirez.com/news/93 只要一个操作非常耗时，就会导致后面的请求都被阻塞住。简单的查询应该不存在这个问题，但如果是删除很多大的key-value。就可能会出现。然后redis在4.0之后引入了多线程异步处理的方式。并增加了一些异步处理命令。 核心问题就是如何处理大的key-value？最具代表性的就是删除大量的key-value。\n渐进式地延迟删除。【将要删除的key分批写入到队列中，但是单线程怎么触发呢？利用定时器渐进的删除。】 队列采用hash table的形式存储。然后利用timer渐进式删除，释放内存。每次删除timer都要知道从哪个地方开始释放内存。然后他采用的是下标的方式记录下次要删除的位置。 但是这种方式存在一个问题，就是进行如下操作 WHILE 1 SADD myset element1 element2 … many many many elements DEL myset END 如果后台删除操作远慢于添加操作，就会导致内存无限增长。【怎么解决，加快删除频率嘛】 他做了两个操作来调整定时器解决这个问题。\n检查内存趋势 动态调整定时器的频率 但是这会导致普通的删除还是要走这个逻辑去做删除。导致正常的删除操作速度下降了65%。\n​\nlazy-free 用一个异步线程去做内存释放操作。 如果有个线程在专门处理内存释放的问题。那么内存释放比内存申请要快得多。 但是引入了多线程就必要要考虑一个新的问题，就是共享数据。 如果数据只存在一个地方，需要的时候，通过引用的方式去获取，不是既节约了内存又节约了时间。 但是还是存在一些问题。举个例子，通过SUNIONSTORE合并两个集合。 如果只是引用其他两个集合的引用。但是这样的话，如果修改新的集合的值，旧集合的值也会跟着改变。 ​\n最终他是通过拷贝数据的方式去解决。（这种方式可能也会引入一些问题， 但是从他后面的处理结果来看，应该还是这种方式比较合适）。 ​\n到这里为止，我们可以看到，在3.2的时候，其实就已经引入了多线程处理。也增加了一个UNLINK命令，就是DEL的异步版本，区别在于，它会先去计算一下删除的开销，开销超过某个值的时候，才用异步的方式进行删除，否则还是用DEL的方式。\n​\n​\n多线程模型 # Redis在6.0版本之后引入了多线程模型。 一般来讲，从单线程的reactor模式变成多线程，应该是master-workers那种形式。就是主线程只负责解释事件。然后把事件分配给不同的worker去处理。 redis的多线程版本区别与正常的master-workers模式，在于， 主线程将命令请求放入到读队列中，然后分配给子线程去解析。主线程自旋等待子线程解析完。 然后执行命令，然后将请求放入写队列中，然后分配给子线程去写入客户端缓存。主线程自旋等待子线程解析完。最后还是由主线程执行最后的响应操作。 ​\n​\n参考文档 # https://segmentfault.com/a/1190000039223696 （一个redis的contributor写的博客） http://antirez.com/news/93 （redis作者写的关于延迟删除的思考） http://antirez.com/latest/0 （redis写的文章的列表） http://redisbook.com/preview/event/file_event.html （redis设计与实现） https://draveness.me/redis-io-multiplexing/ https://zhuanlan.zhihu.com/p/144805500 (redis流程图画的不错)\n","date":"8 February 2022","permalink":"/posts/redis%E7%BD%91%E7%BB%9C%E4%BA%8B%E4%BB%B6%E6%A8%A1%E5%9E%8B/","section":"","summary":"Redis的设计中，有一个被大家熟知的概念，就是在6.","title":"Redis网络事件模型"}]